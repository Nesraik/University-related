{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usern\\anaconda3\\envs\\Speech_Recognition\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio, display\n",
    "sound_path = \"./sample_audio.wav\"\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "original_audio = AudioSegment.from_wav(sound_path)\n",
    "waveform, sample_rate = torchaudio.load(sound_path)\n",
    "\n",
    "waveform_sf, sample_rate = sf.read(sound_path)\n",
    "waveform_librosa, sample_rate = librosa.load(sound_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase or Decrease Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulateVolume(vol_in_DB):\n",
    "    return original_audio + vol_in_DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def manipulatePitch(waveform,sample_rate,num_of_seminodes):\n",
    "    return librosa.effects.pitch_shift(waveform,sr=sample_rate,n_steps=num_of_seminodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fade in or Fade out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fadeInAudio(original_audio,time_in_milsec):\n",
    "    return original_audio.fade_in(time_in_milsec)\n",
    "\n",
    "def fadeOutAudio(original_audio,time_in_milsec):\n",
    "    return original_audio.fade_out(time_in_milsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "Bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
    "labels= Bundle.get_labels()\n",
    "model_sample_rate = Bundle.sample_rate\n",
    "\n",
    "if(sample_rate!=model_sample_rate):\n",
    "    torchaudio.functional.resample(waveform,sample_rate,model_sample_rate)\n",
    "\n",
    "model = Bundle.get_model()\n",
    "with torch.inference_mode():\n",
    "    emission,_ = model(waveform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyDecoderCTC(torch.nn.Module):\n",
    "    def __init__(self, labels):\n",
    "        super().__init__()\n",
    "        self.blank = 0\n",
    "        self.labels = labels\n",
    "    def forward(self, emission: torch.tensor)->str:\n",
    "        indices = torch.argmax(emission,dim=-1)\n",
    "        indices = torch.unique_consecutive(indices,dim=-1)\n",
    "        indices = [i for i in indices if i!=self.blank]\n",
    "        return \"\".join(self.labels[i] for i in indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictText():\n",
    "    Decoder = GreedyDecoderCTC(labels=labels)\n",
    "    transcript = Decoder(emission[0])\n",
    "    result = str(transcript)\n",
    "    result = result.replace(\"|\",\" \")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioAugmentation():\n",
    "    while(True):\n",
    "        print(\"Audio Augmentation Menu\")\n",
    "        print(\"1. Increase or decrease volume\")\n",
    "        print(\"2. Increase or decrease pitch\")\n",
    "        print(\"3. Insert fade in effect\")\n",
    "        print(\"4. Insert fade out effect\")\n",
    "        print(\"5. Back to main menu\")\n",
    "        print(\">> \")\n",
    "        userInput = input()\n",
    "\n",
    "        match userInput:\n",
    "            case \"1\":\n",
    "                while(True):\n",
    "                    vol_in_db = int(input(\"Input volume DB: \"))\n",
    "                    if(vol_in_db > -10000 and vol_in_db<100):\n",
    "                        break\n",
    "                augmented_audio = manipulateVolume(vol_in_db)\n",
    "                \n",
    "                while(True):\n",
    "                    filename = input(\"Input filename(.wav): \")\n",
    "                    if(filename[-4:]==\".wav\"):\n",
    "                        break\n",
    "                \n",
    "                augmented_audio.export(filename,format=\"wav\")\n",
    "            case \"2\":\n",
    "                while(True):\n",
    "                    pitch_rate = int(input(\"Input pitch rate: \"))\n",
    "                    if(pitch_rate > -10 and pitch_rate<10):\n",
    "                        break\n",
    "                augmented_audio = manipulatePitch(waveform_librosa, sample_rate,pitch_rate)\n",
    "                \n",
    "                while(True):\n",
    "                    filename = input(\"Input filename(.wav): \")\n",
    "                    if(filename[-4:]==\".wav\"):\n",
    "                        break\n",
    "                sf.write(filename,augmented_audio,sample_rate,format=\"wav\")\n",
    "            case \"3\":\n",
    "                while(True):\n",
    "                    fade_in_duration = int(input(\"Input fade in duration(in milsec): \"))\n",
    "                    if(fade_in_duration > 0):\n",
    "                        break\n",
    "                augmented_audio = fadeInAudio(original_audio,fade_in_duration)\n",
    "                \n",
    "                while(True):\n",
    "                    filename = input(\"Input filename(.wav): \")\n",
    "                    if(filename[-4:]==\".wav\"):\n",
    "                        break\n",
    "                augmented_audio.export(filename,format=\"wav\") \n",
    "                        \n",
    "            case \"4\":\n",
    "                while(True):\n",
    "                    fade_out_duration = int(input(\"Input fade out duration(in milsec): \"))\n",
    "                    if(fade_out_duration>0):\n",
    "                        break\n",
    "                augmented_audio = fadeOutAudio(original_audio,fade_out_duration)\n",
    "                \n",
    "                while(True):\n",
    "                    filename = input(\"Input filename(.wav): \")\n",
    "                    if(filename[-4:]==\".wav\"):\n",
    "                        break\n",
    "                augmented_audio.export(filename,format=\"wav\")\n",
    "               \n",
    "            case \"5\":\n",
    "                break\n",
    "            case '_':\n",
    "                print(\"Invalid Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript Assistance\n",
      "1. Audio Augmentation\n",
      "2. Predict Text\n",
      "3. Exit\n",
      ">> \n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    print(\"Transcript Assistance\")\n",
    "    print(\"1. Audio Augmentation\")\n",
    "    print(\"2. Predict Text\")\n",
    "    print(\"3. Exit\")\n",
    "    print(\">> \")\n",
    "    userInput = input()\n",
    "\n",
    "    match userInput:\n",
    "        case '1':\n",
    "            audioAugmentation()\n",
    "        case '2':\n",
    "            result = predictText()\n",
    "            print(\"Transciption result: \",result)\n",
    "        case '3':\n",
    "            break\n",
    "        case '_':\n",
    "            print(\"Invalid Input\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Speech_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
